{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the seed of the random number generator to a fixed value\n",
    "# torch.manual_seed(1)    # reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    \n",
    "    # Converts a PIL.Image or numpy.ndarray to\n",
    "    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    \n",
    "    download=DOWNLOAD_MNIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 2000 samples to speed up testing\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "\n",
    "# shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "# unsqueeze: 在size的dim中插入1\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255.   \n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "# from matplotlib import cm\n",
    "# try: from sklearn.manifold import TSNE; HAS_SK = True\n",
    "# except: HAS_SK = False; print('Please install sklearn for layer visualization')\n",
    "# def plot_with_labels(lowDWeights, labels):\n",
    "#     plt.cla()\n",
    "#     X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "#     for x, y, s in zip(X, Y, labels):\n",
    "#         c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "#     plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "# plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.2948 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.6344 | test accuracy: 0.05\n",
      "Epoch:  0 | train loss: 0.2657 | test accuracy: 0.12\n",
      "Epoch:  0 | train loss: 0.1854 | test accuracy: 0.02\n",
      "Epoch:  0 | train loss: 0.1594 | test accuracy: 0.05\n",
      "Epoch:  0 | train loss: 0.3826 | test accuracy: 0.04\n",
      "Epoch:  0 | train loss: 0.0675 | test accuracy: 0.05\n",
      "Epoch:  0 | train loss: 0.1798 | test accuracy: 0.05\n",
      "Epoch:  0 | train loss: 0.1286 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.0893 | test accuracy: 0.06\n",
      "Epoch:  0 | train loss: 0.0338 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.0545 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.2104 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.1565 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.0568 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.0806 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.1389 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.1224 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.1012 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.0716 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.0465 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.0065 | test accuracy: 0.08\n",
      "Epoch:  0 | train loss: 0.1696 | test accuracy: 0.07\n",
      "Epoch:  0 | train loss: 0.1374 | test accuracy: 0.08\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = float(sum(pred_y == test_y)) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "#             if HAS_SK:\n",
    "#                 # Visualization of trained flatten layer (T-SNE)\n",
    "#                 tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "#                 plot_only = 500\n",
    "#                 low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n",
    "#                 labels = test_y.numpy()[:plot_only]\n",
    "#                 plot_with_labels(low_dim_embs, labels)\n",
    "# plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
