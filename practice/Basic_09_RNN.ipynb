{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]    # covert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3130 | test accuracy: 0.09\n",
      "Epoch:  0 | train loss: 1.2984 | test accuracy: 0.57\n",
      "Epoch:  0 | train loss: 0.9107 | test accuracy: 0.68\n",
      "Epoch:  0 | train loss: 0.5702 | test accuracy: 0.77\n",
      "Epoch:  0 | train loss: 0.5697 | test accuracy: 0.86\n",
      "Epoch:  0 | train loss: 0.4369 | test accuracy: 0.86\n",
      "Epoch:  0 | train loss: 0.2822 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.5030 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.0895 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1106 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.2581 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1649 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.0976 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2896 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1265 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0771 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.2990 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1475 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0514 | test accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "            accuracy = float(sum(pred_y == test_y)) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
